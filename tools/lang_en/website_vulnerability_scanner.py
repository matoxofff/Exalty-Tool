import requests
from bs4 import BeautifulSoup
from datetime import datetime
import logging
from colorama import init, Fore, Style
import time

init(autoreset=True)


HEADERS = {
    'User-Agent': 'VulnerabilityScanner/2.0',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5'
}

results = []

def log_and_collect(message, level='info'):
    color = Fore.WHITE
    if level == 'info':
        color = Fore.GREEN
        logging.info(message)
    elif level == 'warning':
        color = Fore.YELLOW
        logging.warning(message)
    elif level == 'error':
        color = Fore.RED
        logging.error(message)
    
    results.append((level, message))
    print(color + message + Style.RESET_ALL)

def validate_url(url):
    """
    Ensure the URL is well-formed and doesn't contain invalid characters.
    """
    try:
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        parsed_url = requests.utils.urlparse(url)
        if not parsed_url.scheme or not parsed_url.netloc:
            raise ValueError(f"Invalid URL format: {url}")
        return url.rstrip('/')
    except Exception as e:
        raise ValueError(f"URL validation error: {str(e)}")

def robust_request(url, retries=3, delay=2, timeout=10):
    """
    Make an HTTP request with retry logic to handle timeouts and connection errors.
    Uses a session object to reuse connections for better performance.
    """
    session = requests.Session()
    session.headers.update(HEADERS)

    for attempt in range(retries):
        try:
            response = session.get(url, timeout=timeout)
            response.raise_for_status()  
            return response
        except (requests.Timeout, requests.ConnectionError) as e:
            log_and_collect(f"[-] Request failed for {url}: {e}. Retry {attempt + 1}/{retries}", 'error')
            time.sleep(delay)
        except requests.HTTPError as e:
            log_and_collect(f"[-] HTTP error for {url}: {e}. Status code: {e.response.status_code}", 'warning')
            return e.response
    return None

def vulnerability_scan(url, paths, scan_name, success_message, error_message):
    """
    Generic function for scanning vulnerabilities based on paths or payloads.
    """
    log_and_collect(f"[*] Scanning for {scan_name}...", 'info')
    found = False
    url = validate_url(url)

    for path in paths:
        test_url = f"{url}/{path}".rstrip('/')
        response = robust_request(test_url)
        if response and response.status_code == 200:
            found = True
            log_and_collect(f"[+] {success_message}: {test_url}", 'info')
        elif response is None:
            log_and_collect(f"[-] {error_message}: {test_url}", 'error')
        elif response.status_code in [401, 403]:
            log_and_collect(f"[!] Potential restricted access detected at {test_url} (Status: {response.status_code})", 'warning')

    if not found:
        log_and_collect(f"[-] No {scan_name} vulnerabilities found.", 'info')

def interesting_paths_scan(url):
    """
    Scan for common paths that could indicate vulnerabilities.
    """
    paths = [
        "admin", "admin/login.php", "backup/db.sql", "private/.env", "uploads/file.txt",
        "api/v1/status", "logs/error.log", "cache/session/", "server-status/index.html", "dashboard/settings.php"
    ]
    vulnerability_scan(url, paths, "interesting paths", "Found interesting path", "Request failed")

def sensitive_file_scan(url):
    """
    Scan for sensitive files that might expose system information.
    """
    sensitive_files = [
        "etc/passwd", "etc/hostname", "var/log/syslog", "root/.ssh/id_rsa", "www/html/.env"
    ]
    vulnerability_scan(url, sensitive_files, "sensitive files", "Found sensitive file", "Request failed")

def xss_scan(url):
    """
    Scan for XSS vulnerabilities by injecting common payloads and checking the response.
    """
    xss_payloads = [
        "<script>alert('XSS')</script>", "<img src=x onerror=alert('XSS')>", "<body onload=alert('XSS')>"
    ]

    log_and_collect("[*] Scanning for XSS vulnerabilities...", 'info')
    found = False
    url = validate_url(url)

    for payload in xss_payloads:
        response = robust_request(url)
        if response and payload in response.text and not any(char in response.text for char in ['&lt;', '&gt;', '&amp;']):
            found = True
            log_and_collect(f"[+] Potential XSS vulnerability detected with payload: {payload}", 'info')

    if not found:
        log_and_collect("[-] No XSS vulnerabilities found.", 'info')

def sql_injection_scan(url):
    """
    Scan for SQL Injection vulnerabilities by injecting common SQL payloads.
    """
    sql_payloads = [
        "'", "' OR '1'='1", "' OR 'a'='a' --"
    ]
    sql_indicators = [
        "SQL syntax", "MySQL", "syntax error", "SQLSTATE", "Warning: mysql_"
    ]

    log_and_collect("[*] Scanning for SQL Injection vulnerabilities...", 'info')
    found = False
    url = validate_url(url)

    for payload in sql_payloads:
        test_url = f"{url}?id={payload}"  
        response = robust_request(test_url)
        if response and any(indicator in response.text for indicator in sql_indicators):
            found = True
            log_and_collect(f"[+] Potential SQL Injection vulnerability detected with payload: {payload}", 'info')

    if not found:
        log_and_collect("[-] No SQL Injection vulnerabilities found.", 'info')

def directory_traversal_scan(url):
    """
    Scan for directory traversal vulnerabilities by injecting path traversal payloads.
    """
    traversal_payloads = [
        "../../../../etc/passwd", "../../../../windows/win.ini"
    ]
    vulnerability_scan(url, traversal_payloads, "directory traversal", "Potential Directory Traversal vulnerability detected", "Request failed")

def main():
    url = input("Enter the website URL to scan (e.g., https://example.com): ").strip()
    try:
        url = validate_url(url)
    except ValueError as e:
        log_and_collect(f"[-] Invalid URL: {e}", 'error')
        return

    log_and_collect(f"[*] Starting vulnerability scan for {url}", 'info')
    
    interesting_paths_scan(url)
    sensitive_file_scan(url)
    xss_scan(url)
    sql_injection_scan(url)
    directory_traversal_scan(url)

    log_and_collect(f"[*] Scan completed for {url}", 'info')

if __name__ == "__main__":
    main()
